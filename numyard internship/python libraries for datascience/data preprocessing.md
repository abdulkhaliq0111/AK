
# Data manipulation

Here are Python libraries that will help you to clean any messy data you might be faced with and learn how to manipulate it so our data is ready for modeling.

**Scipy**
-SciPy is a free and open-source Python library used for scientific computing and technical computing. It is based on the NumPy concept to deal with complex mathematical problems.

**Numpy**
-NumPy is the most essential library to perform mathematical and statistical operations. It works perfectly well for multi-dimensional arrays and matrices multiplication. NumPy is very convenient to work with, especially for matrix multiplication and reshaping and more helpful in machine learning.

**Pandas**
-Pandas is a fast, powerful, flexible, and easy to use open-source data analysis and manipulation tool, built on top of the Python programming language. The crux behind pandas is a dataframe object that is the powerful in-memory table that allows you to represent tabular data.

**dirty_cat** - Encoding methods for dirty categorical variables.

**Impyute** - Data imputations library to preprocess datasets with missing data.

**eif** - Extended Isolation Forest for Anomaly Detection.

**Mlpy**
-Mlpy is a Python module for Machine Learning built on top of NumPy/SciPy and the GNU Scientific Libraries. Suited for the general-purpose machine learning task.
It is aimed at finding a reasonable compromise among modularity, maintainability, reproducibility, usability, and efficiency


**PyOD**
-PyOD is a scalable and comprehensive Python toolkit for detecting outliers in multivariate data.
PyOD already supports around 20 classical outlier detection algorithms which can be used in both academic and commercial projects

**Python-tabulate**

*Printing small tables without the hassle: just one function call, formatting is guided by the data itself
*Authoring tabular data for lightweight plain-text markup: multiple output formats suitable for further editing or transformation

**kmodes** - k-modes and k-prototypes clustering algorithm.

**annoy** - Approximate Nearest Neighbors.

**datacleaner** - Automatically cleans data sets and readies them for analysis.

**n2** - Lightweight approximate Nearest Neighbor library which runs faster even with large datasets.


**Ftfy: fixes text for you**
-The goal of ftfy is to take in bad Unicode and output good Unicode, for use in your Unicode-aware code. This is different from taking in non-Unicode and outputting Unicode, which is not a goal of ftfy. Ftfy helps those who help themselves.

**Beautifier**
-A simple library to clean up and prettify URL patterns, domains, and so on. The library helps to clean Unicode, special characters, and unnecessary redirection patterns from the URLs and gives you clean data.

**Arrow**
-Arrow is a Python library that offers a sensible and human-friendly approach to creating, manipulating, formatting, and converting dates, times, and timestamps. It implements and updates the DateTime type, plugging gaps in functionality, and providing an intelligent module API that supports many common creation scenarios.

**engarde** - Defensive data analysis.

**Scrubadub**
-It is used to remove personally identifiable information from free text. Sometimes we have additional metadata about the people we wish to anonymize. Other times we donâ€™t. This package makes it easy to seamlessly scrub personal information from free text, without compromising the privacy of the people we are trying to protect.

**engarde** - Defensive data analysis.

**categorical-encoding** - sklearn compatible categorical variable encoders.

**fancyimpute** - Multivariate imputation and matrix completion algorithms.

**Data cleaner**
-A Python tool that automatically cleans data sets and readies them for analysis.  It saves you a ton of time encoding and cleaning your data once it's already in a format that pandas Data Frames can handle.


**scikit-feature** - Filter methods for feature selection.

**mifs** - Parallelized Mutual Information based Feature Selection module.

**skggm** - Scikit-learn compatible estimation of general graphical models.

**featexp** - Feature exploration for supervised learning.

**feature_engine** - Feature engineering package with sklearn like functionality.

**stumpy** - STUMPY is a powerful and scalable Python library that can be used for a variety of time series data mining tasks.


**Pendulum**
-The pendulum is a Python package to ease datetimes manipulation. It provides classes that are drop-in replacements for the native ones (they inherit from them).
It is for people who get frustrated when working with date-times in Python

**Dora**
-Dora is designed for exploratory analysis; it contains convenience functions for data cleaning, feature selection & extraction, visualization, partitioning data for model validation, and versioning transformations. Reading data with missing and poorly scaled values, Imputing missing values, Scaling values of input variables

**raccoon** - DataFrame with fast insert and appends.




# |   **PIPELINES**  |

A pipeline is what chains several steps together, once the initial exploration is done. Here are Python libraries that will help you to create pipelines.

**pdpipe** - Easy pipelines for pandas DataFrames. a simple framework for serializable, chainable, and verbose pandas pipelines. Its intuitive API enables you to generate, using only a few lines

**SSPipe** - Python pipe (|) operator with support for DataFrames and Numpy and Pytorch.

**pandas-ply** - Functional data manipulation for pandas. pandas compatible

**Dplython** - Dplyr for Python. R inspired/ported lib

**sklearn-pandas** - pandas integration with sklearn. sklearn pandas compatible

**Dataset** - Helps you conveniently work with random or sequential batches of your data and define data processing.

**pyjanitor** - Clean APIs for data cleaning. pandas compatible

**Meza** - A Python toolkit for processing tabular data. It has a functional programming style API, excels at reading/writing large files,
and can process 10+ file types.

**Prodmodel** - Build a system for data science pipelines.

**dopanda** - Hints and tips for using pandas in an analysis environment.



